{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83ed0194-fcec-4299-9ffd-cccc861119bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import asyncio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIATE PROXY POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_pool = [\n",
    "    '154.6.98.26:3128',\n",
    "    '38.62.223.149:3128',\n",
    "    '103.118.78.194:80',\n",
    "    '38.62.222.32:3128',\n",
    "    '154.6.97.157:3128',\n",
    "    '154.6.97.145:3128',\n",
    "    '38.62.223.220:3128',\n",
    "    '38.62.223.149:3128'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE TEST PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5ad0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define custom options for the Selenium driver\n",
    "# options = Options()\n",
    "\n",
    "# options.add_argument(f'--proxy-server={proxy_pool[7]}')\n",
    "\n",
    "# # create the ChromeDriver instance with custom options\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# driver.get('http://httpbin.org/ip')\n",
    "# # driver.get('https://www.malt.fr/profile/luccharlopeau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BACKUP CSV CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def backup_csv(df):\n",
    "    while True:\n",
    "        await asyncio.sleep(30) # wait 1800 seconds (30 minutes)\n",
    "        print('Saving data to csv')\n",
    "        await df.to_csv('raw_data.csv', index=False)\n",
    "        print('Data saved to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets a df and gives the next profile to scrap, when its scrapped it updates the df\n",
    "def get_next_profile(df):\n",
    "    # get the first profile that is not scrapped\n",
    "    next_profile = df[df['scraped']==False].iloc[0]\n",
    "    # update the df\n",
    "    df.loc[df['profil']==next_profile['profil'], 'scraped'] = True\n",
    "    return df, next_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRAP USER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2acab102-8494-4c6a-826b-db2e58992ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrap_user(row, proxy):\n",
    "    \"\"\"\n",
    "    Scrap the user profile\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row: dict\n",
    "        The row of the dataframe\n",
    "    proxy: str\n",
    "        The proxy to use\n",
    "    \"\"\"\n",
    "    \n",
    "    link = row['link']\n",
    "    creation_date = row['creation_date']\n",
    "    profil = row['profil']\n",
    "\n",
    "    # define custom options for the Selenium driver\n",
    "    options = Options()\n",
    "\n",
    "    options.add_argument(f'--proxy-server={proxy}')\n",
    "    options.add_argument(\"window-size=400,200\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"enable-automation\")\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    # create the ChromeDriver instance with custom options\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    driver.get(link)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    data = {}\n",
    "\n",
    "    price_element = soup.find('div', {'data-testid': 'profile-price'})\n",
    "    if price_element:\n",
    "        price = price_element.find('span', class_='block-list__price').text\n",
    "        data['price'] = price.strip()\n",
    "    \n",
    "    # Récupérer l'expérience\n",
    "    experience_element = soup.find('span', string='Expérience')\n",
    "    if experience_element:\n",
    "        experience = experience_element.find_next('span', class_='profile-indicators-content').text\n",
    "        data['experience'] = experience.strip()\n",
    "    \n",
    "    # Récupérer le taux de réponse\n",
    "    response_rate_element = soup.find('span', string='Taux de réponse')\n",
    "    if response_rate_element:\n",
    "        response_rate = response_rate_element.find_next('span', class_='profile-indicators-content').text\n",
    "        data['response_rate'] = response_rate.strip()\n",
    "    \n",
    "    # Récupérer le temps de réponse\n",
    "    response_time_element = soup.find('span', string='Temps de réponse')\n",
    "    if response_time_element:\n",
    "        response_time = response_time_element.find_next('span', class_='profile-indicators-content').text\n",
    "        data['response_time'] = response_time.strip()\n",
    "        \n",
    "    # Récupérer le nom \n",
    "    name_element = soup.find('div', {'data-testid': 'profile-fullname'})\n",
    "    if name_element:\n",
    "        name = name_element.text\n",
    "        data['name'] = name.strip()\n",
    "        \n",
    "    # Récupérer le métier\n",
    "    headline_element = soup.find('div', {'data-testid': 'profile-headline'})\n",
    "    if headline_element:\n",
    "        headline = headline_element.text\n",
    "        data['headline'] = headline.strip()\n",
    "        \n",
    "    # Récupérer le nombre de missions\n",
    "    missions_element = soup.find('div', {'data-testid': 'profile-counter-missions'})\n",
    "    if missions_element:\n",
    "        missions = missions_element.find('strong').text\n",
    "        data['missions'] = missions.strip()\n",
    "        \n",
    "    # Récupérer toutes les catégories\n",
    "    categories_elements = soup.find_all('li', {'class': 'categories__list-item'})\n",
    "    categories = [category.find('a').text for category in categories_elements]\n",
    "    data['categories'] = categories\n",
    "    \n",
    "    \n",
    "    # Récupérer les compétences\n",
    "    competences_element = soup.find_all('div', {'class': 'profile-expertises__content-list-item__label'})\n",
    "    competences = [competence.find('a', class_='joy-link joy-link_teal').text.strip() for competence in competences_element]\n",
    "\n",
    "    data['competences'] = competences\n",
    "    \n",
    "    # Récupérer le statut \"Supermalter\"\n",
    "    supermalter_element = soup.find('span', class_='joy-badge-level__tag blue')\n",
    "    if supermalter_element:\n",
    "        supermalter = supermalter_element.get_text(strip=True)\n",
    "        data['supermalter'] = supermalter\n",
    "        \n",
    "    # Récupérer la localisation\n",
    "    location_element = soup.find('dl', {'class': 'profile__location-and-workplace-preferences__item'})\n",
    "    if location_element:\n",
    "        location_label = location_element.find('dt', {'data-testid': 'profile-location-address-label'})\n",
    "        location_value = location_element.find('dd', {'data-testid': 'profile-location-preference-address'})\n",
    "\n",
    "        if location_label and location_value:\n",
    "            location = {location_label.text: location_value.text}\n",
    "            data['location'] = location\n",
    "            \n",
    "    # Récupérer la préférence de télétravail\n",
    "    teletravail_element = soup.find('dl', {'class': 'profile-page-mission-preferences__item'})\n",
    "    if teletravail_element:\n",
    "        teletravail_label = teletravail_element.find('dt')\n",
    "        teletravail_value = teletravail_element.find('dd')\n",
    "\n",
    "        if teletravail_label and teletravail_value:\n",
    "            teletravail_preference = {teletravail_label.text: teletravail_value.text}\n",
    "            data['teletravail_preference'] = teletravail_preference\n",
    "            \n",
    "    # Récupérer le nombre de recommandations\n",
    "    recommendations_element = soup.find('span', {'data-testid': 'profile-counter-recommendations'})\n",
    "    if recommendations_element:\n",
    "        recommendations_count = int(recommendations_element.text.split()[0])\n",
    "        data['recommendations'] = recommendations_count   \n",
    "        \n",
    "\n",
    "    # Récupérer le message de présentation\n",
    "    presentation_element = soup.find('div', {'class': 'profile-description__content'})\n",
    "    if presentation_element:\n",
    "        presentation_message = presentation_element.get_text(strip=True)\n",
    "        data['presentation'] = presentation_message\n",
    "        \n",
    "    # add link of the profile\n",
    "    data['link'] = row['link']\n",
    "    \n",
    "    # add created date\n",
    "    data['creation_date'] = row['creation_date']\n",
    "    \n",
    "    # add name to the data\n",
    "    data['profil'] = row['profil']\n",
    "          \n",
    "    driver.quit() # close the browser\n",
    "    # time.sleep(5) # wait for 5 seconds to avoid getting banned\n",
    "    \n",
    "    return data # return the data scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrap_all_users_proxy(df): # links is a list of links to scrap.\n",
    "    \"\"\"\n",
    "    Scrap the profile of every link in the list of links.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    links : list\n",
    "        List of links to scrap.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    all_data : dataFrame\n",
    "        DataFrame containing all the data scrapped.\n",
    "    \"\"\"\n",
    "    all_data = [] # list to store all the data scrapped\n",
    "    \n",
    "    links = df['link'].tolist()\n",
    "    creation_date = df['creation_date'].tolist()\n",
    "    profils = df['profil'].tolist()\n",
    "    \n",
    "    # backup_csv(df)\n",
    "    \n",
    "    for i in range(len(links)):\n",
    "        row = {\n",
    "            'link': links[i],\n",
    "            'creation_date': creation_date[i],\n",
    "            'profil': profils[i]\n",
    "        }\n",
    "        scrapped_user = await scrap_user(row, proxy_pool[0]) # scrap the user\n",
    "        print(\"Scraped \",i,\" user: \",scrapped_user)\n",
    "        \n",
    "        all_data.append(scrapped_user)\n",
    "        \n",
    "    return all_data # return the list of data scrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THE SCRIPT WITH THE LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "703537a8-6bf8-44e5-bd74-0948d0c3ddb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'asyncio' has no attribute 'ThreadPoolExecutor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m scrap_all_users_proxy(profile_links)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m main()\n",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m scrap_all_users_proxy(profile_links)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mScrap the profile of every link in the list of links.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m    DataFrame containing all the data scrapped.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Create a pool of asyncio tasks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m asyncio\u001b[39m.\u001b[39;49mThreadPoolExecutor(max_workers\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     all_data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m executor\u001b[39m.\u001b[39mmap(scrap_user, df\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m), proxy_pool)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X16sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mreturn\u001b[39;00m all_data\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'asyncio' has no attribute 'ThreadPoolExecutor'"
     ]
    }
   ],
   "source": [
    "profile_links = pd.read_csv('../data/links.csv')\n",
    "profile_links['profil'] = profile_links['profil'].apply(lambda x: x.replace('https://www.malt.fr/profile/', ''))\n",
    "\n",
    "# add column link to the DataFrame\n",
    "profile_links['link'] = profile_links['profil'].apply(lambda x: f'https://www.malt.fr/profile/{x}')\n",
    "\n",
    "profile_links['scraped'] = False # add column scraped to the DataFrame\n",
    "\n",
    "# get first 10 rows of the DataFrame\n",
    "profile_links = profile_links.iloc[:10]\n",
    "\n",
    "async def main():\n",
    "    data = await scrap_all_users_proxy(profile_links)\n",
    "    return data\n",
    "\n",
    "data = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'price': '300\\xa0€',\n",
       "  'experience': '15 ans et +',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': '12h',\n",
       "  'name': 'Brice Tillet',\n",
       "  'headline': 'Composer / Sound Designer / Music Producer',\n",
       "  'categories': ['Sound Designer'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'Paris, France'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': 'Paris et 50km autour'},\n",
       "  'recommendations': 6,\n",
       "  'presentation': \"Bonjour,je suis musicien, compositeur et sound designer depuis 2005.J'aime composer à l'image, travailler les textures sonores, jouer avec le rythme et les silences.N'hésitez pas à me contacter !Brice\",\n",
       "  'link': 'https://www.malt.fr/profile/bricetillet',\n",
       "  'creation_date': '2014-01-08',\n",
       "  'profil': 'bricetillet'},\n",
       " {'price': '250\\xa0€',\n",
       "  'experience': '-',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': 'Quelques jours',\n",
       "  'name': 'Mickael M.',\n",
       "  'headline': 'Graphiste',\n",
       "  'categories': ['Graphiste'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': '21000 Dijon, France'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': 'Dijon et 50km autour'},\n",
       "  'presentation': 'Passionné depuis mon enfance par le graphisme, j’ai décidé de me lancer en tant que freelance. J’ai commencé assez tôt à utiliser le logiciel Photoshop (au collège). Je passais mon temps libre à retoucher des photos, faire des montages que je mettais en ligne sur mes différents blogs.Après l’obtention de mon baccalauréat au lycée Stephen Liegeard à Brochon, je suis parti étudier le graphisme à l’Institut de l’Internet et du Multimédia au pôle universitaire Leonard de Vinci (Paris La Defense). A l’issu de mes 3 années en option communication visuelle, j’ai obtenu un bachelor chef de projet multimédia. Après mes études, je suis retourné vivre à Dijon et j’ai créé mon activité de graphiste freelance Ka Design.',\n",
       "  'link': 'https://www.malt.fr/profile/mickaelmolina',\n",
       "  'creation_date': '2013-08-02',\n",
       "  'profil': 'mickaelmolina'},\n",
       " {'price': '520\\xa0€',\n",
       "  'experience': '8-15 ans',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': '1h',\n",
       "  'name': 'Adriana Lyra',\n",
       "  'headline': 'UX/UI Designer Senior ⚡️ Brand Designer',\n",
       "  'missions': '21',\n",
       "  'categories': ['UI Designer', 'UX Designer'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'Paris, France'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': 'Paris et 50km autour'},\n",
       "  'recommendations': 7,\n",
       "  'presentation': 'Créative, curieuse et rigoureuse, je suis passionnée par tout ce qui nourrit la culture digitale. Bénéficiant d’une forte expérience dans le graphisme print et web, je me suis spécialisée dans la conception d’expériences digitales centrées utilisateur. J’interviens selon vos besoins dès la phase de recherche utilisateur jusqu’à la conception visuelle de vos interfaces graphiques ainsi que les prototypes fonctionnels.MÉTHODOLOGIE DESIGN THINKING / AGILE :User Research : Étude de marché, Sondages, Interviews, Empathy Map, Étude ethnographique, Problem Statement…Définition du problème : How Might We, Personas, Story boards, User Flows, User journey…Idéation : Brainstorming, crazy 8, Sketches, Moscow, Affinity diagram…Prototypage : Wireframes, Architecture de l’information, Prototypes Low/Mid/High-fidelity, Design System…Tests : Usabilité, Désirabilité, A/B tests…BRANDING :identités visuelles / chartes graphiquesOUTILS :Figma, Invision, Suite Adobe (Indesign, Illustrator, Photoshop), Miro, Mural…',\n",
       "  'link': 'https://www.malt.fr/profile/adrianalyra',\n",
       "  'creation_date': '2013-07-18',\n",
       "  'profil': 'adrianalyra'},\n",
       " {'price': '700\\xa0€',\n",
       "  'experience': '-',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': '1h',\n",
       "  'name': 'Alexandre Labayle',\n",
       "  'headline': 'Consultant décisionnel Senior',\n",
       "  'categories': [],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': ''},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': ' et 50km autour'},\n",
       "  'presentation': \"Consultant Senior en Business Intelligence , 14 ans d'expérience.Certifié SAP Business Objects et Microsoft BI. Missions d'architecture technique (cluster SAP BI ,implémentation de sécurité). Modélisation et alimentation de DatawareHouse (Dataservices / SSIS/SSAS) . Création de rapports Excel PowerPivot/Sap Business Objects .Création d'univers ou de cubes SSAS.\",\n",
       "  'link': 'https://www.malt.fr/profile/alexandrelabayle',\n",
       "  'creation_date': '2014-02-04',\n",
       "  'profil': 'alexandrelabayle'},\n",
       " {'price': '40\\xa0€',\n",
       "  'experience': '-',\n",
       "  'response_time': '1h',\n",
       "  'name': 'Nacera  TIZI',\n",
       "  'headline': 'Commerciale Freelance',\n",
       "  'categories': ['Business developers'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'Tanger, Tanger-Tétouan, Maroc'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': 'Tanger et 50km autour'},\n",
       "  'presentation': \"Parce que La ville de Tanger tend à devenir l'une des plus importantes au Maroc. Placée deuxième ville économique je suis aujourd'hui en mesure de développer votre chiffre d'affaire au Maroc.Diplômée d’un Master 2 Économie gestion des entreprises, spécialité contrôle de gestion Audit à l'université de Lille 1 en France. J’ai eu l’occasion d’effectuer plusieurs jobs dans le domaine du commerce, ainsi faites moi confiance.\",\n",
       "  'link': 'https://www.malt.fr/profile/naceratizi',\n",
       "  'creation_date': '2014-02-22',\n",
       "  'profil': 'naceratizi'},\n",
       " {'price': '550\\xa0€',\n",
       "  'experience': '8-15 ans',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': '1h',\n",
       "  'name': 'Aurélien D.',\n",
       "  'headline': 'SysOps, DevOps et développeur web',\n",
       "  'missions': '12',\n",
       "  'categories': ['Administrateur base de données',\n",
       "   'Administrateur Système et Réseaux',\n",
       "   'Développeur CMS',\n",
       "   'Développeur ERP',\n",
       "   'Développeur Web Back-end',\n",
       "   'Développeur Web Front-end',\n",
       "   'DevOps',\n",
       "   'Intégrateur Web'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'La Rochelle, France'},\n",
       "  'teletravail_preference': {'Télétravail': 'Effectue ses missions majoritairement à distance'},\n",
       "  'recommendations': 1,\n",
       "  'presentation': 'SysOps (unix) depuis 5 ans et DevOps depuis 4 ans, j\\'ai également une expérience de plus de 12 ans en tant que développeur web full stack.En tant qu\\'administrateur système Unix expérimenté, je peux vous aider à gérer et à optimiser votre serveur Unix. Que ce soit pour configurer un nouveau serveur, résoudre des problèmes de performance ou de sécurité, ou automatiser des tâches répétitives, je peux vous offrir une assistance professionnelle pour assurer le bon fonctionnement de votre système.Les services que je peux fournir incluent :- Installation et configuration de système d\\'exploitation (Unix / Linux uniquement)- Configuration et gestion des services réseau (comme SSH, FTP, DNS)- Gestion des utilisateurs et des groupes- Sauvegarde et restauration de données- Mise en place de stratégies de sécurité- Optimisation des performances- Automatisation des tâches à l\\'aide de scripts (bash, python, etc.)- Diagnostique et résolution des problèmesJe m\\'efforce de fournir un service rapide et efficace, avec une communication claire et régulière pour vous tenir informé de l\\'avancée de la mission.Au niveau du développement web j\\'aime créer des solutions clé en main \"sur mesure\", sans forcément partir d\\'un existant. Mais je sais aussi bien reprendre un projet déjà développé afin de le maintenir ou l\\'améliorer.Je souhaite apporter mon expertise et mes compétences au service de projets divers et variés mais également confirmer voire élargir mes connaissances.N\\'hésitez pas à me contacter pour une première discussion de votre projet, je suis joignable par téléphone, malt, email ou tout simplement autour d\\'un café :).À bientôt !',\n",
       "  'link': 'https://www.malt.fr/profile/aureliendazy',\n",
       "  'creation_date': '2013-06-06',\n",
       "  'profil': 'aureliendazy'},\n",
       " {'price': '235\\xa0€',\n",
       "  'experience': '-',\n",
       "  'response_rate': '33%',\n",
       "  'response_time': '12h',\n",
       "  'name': 'Youri Galescot',\n",
       "  'headline': 'Développeur web frontend et backend',\n",
       "  'categories': [],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'Paris, France'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': 'Paris et 50km autour'},\n",
       "  'presentation': \"Bonjour,Je suis développeur frontend et backend freelance depuis 2012.Diplômé d'un master en systèmes d'information je maîtrise bien le design et le développement de sites web, domaine qui me passionne. Je peux créer aussi bien des sites web vitrines que des sites web dynamiques, dotés d’un CMS.Je code en HTML5/CSS3, PHP, jQuery, sur des frameworks différents comme CodeIgniter, Symfony 2, sur le CMS Wordpress ainsi que sur Bootstrap.J'ai créé plusieurs sites web dans le cadre de mon activité d'autoentrepreneur.Mes sites sont optimisés pour les supports mobiles et pour le référencement naturel.Si vous êtes intéressés par mon profil, n'hésitez pas à me contacter.\",\n",
       "  'link': 'https://www.malt.fr/profile/yourigalescot',\n",
       "  'creation_date': '2014-02-18',\n",
       "  'profil': 'yourigalescot'},\n",
       " {'price': '300\\xa0€',\n",
       "  'experience': '-',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': 'Quelques jours',\n",
       "  'name': 'Siobhan Engelmann',\n",
       "  'headline': 'Traduction Translation',\n",
       "  'categories': ['Traducteur'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'Metz, France'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': 'Metz et 50km autour'},\n",
       "  'presentation': 'English native speaker, degree qualified engineer, translate technical / engineering  texts from French, German and Italian into English.  All formats accepted including http, Quick turnaround.  15cents / word',\n",
       "  'link': 'https://www.malt.fr/profile/siobhanengelmann',\n",
       "  'creation_date': '2014-02-11',\n",
       "  'profil': 'siobhanengelmann'},\n",
       " {'price': '350\\xa0€',\n",
       "  'experience': '8-15 ans',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': '1h',\n",
       "  'name': 'Julien Trezeux',\n",
       "  'headline': 'directeur artistique - graphiste - illustrateur',\n",
       "  'categories': ['Photographe', 'Graphiste', 'Illustrateur'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': 'Paris, France / www.graphicfactory.fr'},\n",
       "  'teletravail_preference': {'Télétravail': 'Effectue ses missions majoritairement à distance'},\n",
       "  'recommendations': 3,\n",
       "  'presentation': \"Graphiste et directeur artistique depuis 2007, j'ai travaillé en agence de publicité pour le monde du jeu vidéo, du luxe et de la bijouterie jusqu'en 2009 avant de me mettre à mon compte en tant que Directeur artistique.Je collabore depuis avec des agences d'architectures, maisons horlogères, fédérations nationales ou sportives.\",\n",
       "  'link': 'https://www.malt.fr/profile/julientrezeux',\n",
       "  'creation_date': '2014-02-12',\n",
       "  'profil': 'julientrezeux'},\n",
       " {'price': '695\\xa0€',\n",
       "  'experience': '-',\n",
       "  'response_rate': '100%',\n",
       "  'response_time': '1h',\n",
       "  'name': 'Valérie Vanhamme-Vermeulen',\n",
       "  'headline': 'Consultante marketing & communication spécialisée',\n",
       "  'categories': ['Consultant Communication'],\n",
       "  'competences': [],\n",
       "  'location': {'Localisation': '32800 Réans'},\n",
       "  'teletravail_preference': {'Peut travailler dans vos locaux à': '32800 Réans et 50km autour'},\n",
       "  'presentation': \"Je possède une expérience de plus de 13 ans dans le domaine du marketing des services, expérience forgée auprès d’acteurs majeurs du secteur tels que PricewaterhouseCoopers et Allen & Overy.Au cours de ma carrière, j'ai assisté de nombreux avocats dans leur stratégie et le développement de leurs affaires. Mon expérience inclut, entre autres, la préparation de business plans, le calcul et la mise en place de stratégies dans le cadre de négociations d’honoraires, le développement, l’optimalisation et la gestion d’outils crm ainsi que la rédaction d’offres adaptées aux demandes des clients.Je me suis également chargée de la rédaction de diverses communications (internes et externes), la mise en place d’une stratégie liée à l’utilisation des médias sociaux et l’organisation d’événements clients haut de gamme et novateurs.Je propose mes services qui s’adressent principalement aux cabinets d’avocats d’affaires. Je m'efforce d’apporter un regard neuf et extérieur aux activités marketing de nos clients. Je les accompagne dans toutes les phases de leur projet marketing, depuis la création jusqu’à la mise en place. Je mets un point d’honneur à délivrer des prestations répondant à de hautes exigences de qualité et de réactivité. Je suis flexible et travaille en collaboration étroite avec les associés responsables / l’équipe existante.\",\n",
       "  'link': 'https://www.malt.fr/profile/valerievanhammevermeulen',\n",
       "  'creation_date': '2014-02-22',\n",
       "  'profil': 'valerievanhammevermeulen'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE DATA TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61e4291-0e0e-47c2-bf83-2913657d7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, csv_filename):\n",
    "    # Assurez-vous que la liste de données n'est pas vide\n",
    "    if not data:\n",
    "        print(\"Aucune donnée à enregistrer.\")\n",
    "        return\n",
    "\n",
    "    # Créez une liste de noms de colonnes pour le CSV en incluant les nouveaux éléments\n",
    "    fieldnames = ['name', 'headline', 'price', 'experience', 'response_rate', 'response_time', 'missions', 'categories', 'competences', 'supermalter', 'location','presentation', 'recommendations', 'teletravail_preference']\n",
    "\n",
    "    # Ouvrir le fichier CSV en mode écriture\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Écrire les en-têtes\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Écrire les données\n",
    "        for entry in data:\n",
    "            writer.writerow(entry)\n",
    "\n",
    "    print(f\"Données enregistrées dans {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6ce171a-cfba-4045-a89e-d83c0d4af58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 'profil', 'creation_date', 'link'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m csv_filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmalt_data.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m save_to_csv(data, csv_filename)\n",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Écrire les données\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m data:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         writer\u001b[39m.\u001b[39;49mwriterow(entry)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/scrapping/scripts/scrap_profile_proxy.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDonnées enregistrées dans \u001b[39m\u001b[39m{\u001b[39;00mcsv_filename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/csv.py:154\u001b[0m, in \u001b[0;36mDictWriter.writerow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwriterow\u001b[39m(\u001b[39mself\u001b[39m, rowdict):\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter\u001b[39m.\u001b[39mwriterow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_to_list(rowdict))\n",
      "File \u001b[0;32m/usr/lib/python3.11/csv.py:149\u001b[0m, in \u001b[0;36mDictWriter._dict_to_list\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    147\u001b[0m     wrong_fields \u001b[39m=\u001b[39m rowdict\u001b[39m.\u001b[39mkeys() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfieldnames\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m wrong_fields:\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdict contains fields not in fieldnames: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m                          \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mrepr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m wrong_fields]))\n\u001b[1;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m (rowdict\u001b[39m.\u001b[39mget(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestval) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfieldnames)\n",
      "\u001b[0;31mValueError\u001b[0m: dict contains fields not in fieldnames: 'profil', 'creation_date', 'link'"
     ]
    }
   ],
   "source": [
    "csv_filename = 'malt_data.csv'\n",
    "save_to_csv(data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
